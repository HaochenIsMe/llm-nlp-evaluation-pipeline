# 基于 NLP / LLM 的文本主题分类评测 Pipeline

## 目录
- [项目背景与目的](#项目背景与目的)
- [研究假设](#研究假设)
- [方法与整体流程](#方法与整体流程)
- [基线方法](#基线方法)
  - [Baseline A：传统 NLP 方法](#baseline-a传统-nlp-方法)
  - [Baseline B：基于 LLM 的方法](#baseline-b基于-llm-的方法)
- [数据集说明](#数据集说明)
- [评测指标](#评测指标)
- [实验结果展示](#实验结果展示)
- [项目限制与不足](#项目限制与不足)
- [项目总结](#项目总结)

---

## 项目背景与目的

文本主题分类是自然语言处理（NLP）中一个基础且具有代表性的任务，在搜索、推荐、内容理解等场景中被广泛使用。

随着大语言模型（LLM）的出现，传统 NLP 方法与基于 LLM 的方法在同一任务下的表现差异，仍然需要在统一的评测框架下进行对比与分析。

本项目的目标是：

- 构建一个端到端的文本主题分类评测 pipeline  
- 在相同数据集和评测指标下，对比传统 NLP 方法与 LLM 方法的效果  
- 分析不同方法的优势、局限性及其适用场景  

本项目侧重于**流程完整性、评测一致性和结果可解释性**。

---

## 研究假设

在统一的数据集与评测指标下：

- 不同建模方法（传统 NLP 方法 vs 基于 LLM 的方法）在文本主题分类任务上的表现存在系统性差异  
- LLM 方法在语义理解能力上可能具有优势，但同时也受到稳定性、成本等因素的影响  

---

## 方法与整体流程

本项目采用统一的处理流程，以保证不同方法在相同条件下进行公平对比：

1. 数据加载与清洗  
2. 文本预处理（如分词、向量化等）  
3. 使用不同方法进行文本主题分类推理  
4. 统一计算评测指标  
5. 对实验结果进行对比与分析  

整体流程强调**可复现性**和**一致性**。

---

## 基线方法

### Baseline A：传统 NLP 方法

- 使用 TF-IDF 进行文本特征表示  
- 采用线性分类器（如 Logistic Regression）进行主题分类  

该方法作为经典文本分类基线，具有实现简单、可解释性强的特点。

---

### Baseline B：基于 LLM 的方法

- 使用预训练大语言模型进行文本主题分类  
- 采用零样本（zero-shot）或少样本（few-shot）提示方式  

该方法用于评估 LLM 在无需显式任务训练情况下的分类能力。

---

## 数据集说明

- 使用公开可获取的文本主题分类数据集  
- 数据集包含多个主题类别  
- 本项目使用数据集的子集进行实验与验证  

数据集仅用于学习与实验目的。

---

## 评测指标

为全面评估模型性能，本项目采用以下指标：

- Accuracy  
- Precision  
- Recall  
- F1-score  

其中，F1-score 用于在类别分布不均衡的情况下，更稳健地衡量模型整体性能。

---

## 实验结果展示

通过统一评测框架，对不同方法的分类效果进行量化对比，并分析各方法在不同指标下的表现差异。

实验结果以表格形式呈现，便于直观比较。

---

## 项目限制与不足

- 数据集规模有限，实验结论的泛化能力存在限制  
- LLM 方法对提示词（prompt）较为敏感  
- 当前评测仅关注分类效果，未纳入推理延迟与计算成本  
- 实验仅覆盖单一文本任务，尚未扩展至更多 NLP 场景  

---

## 项目总结

本项目通过构建统一的文本主题分类评测 pipeline，对传统 NLP 方法与基于 LLM 的方法进行了系统性对比。

项目强调流程完整性、评测一致性与结果可解释性，为后续更复杂的 NLP / LLM 应用提供参考。

---

TODO：
1. 选一个公开、可查、多主题的数据集
2. 数据清洗
    1. 为什么要清洗
    2. 清洗了什么
3. 文本预处理
4. 传统 NLP 建模
    1. TF-IDF 实装
    2. 线性分类器实装
5. LLM 建模
    1. zero-shot / few-shot
    2. 用哪个 LLM
    3. 如何推理
6. 文本主题分类推理
7. 指标计算与结果对比分析

TODO：
1. README里面写出我选择了这个而不选择别的的理由
2. 自己搞懂原理，可以口头回答