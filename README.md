# 基于 NLP / LLM 的文本主题分类评测 Pipeline

## 项目背景与目的（Problem）

在实际工程与算法应用中，文本主题分类是一个非常基础但具有代表性的 NLP 任务。
随着大语言模型（LLM）的出现，传统 NLP 方法与 LLM 方法在同一任务下的表现差异，仍然需要在统一评测框架下进行对比和分析。

本项目的目标是：
- 构建一个端到端的文本主题分类评测 pipeline
- 在相同数据集与评测指标下，对比传统 NLP 方法与 LLM 方法的效果
- 分析不同方法的优势、局限性及适用场景

---

## 研究假设（Hypothesis）

在统一的数据集和评测指标下：
- 不同建模方法（传统 NLP vs 基于 LLM 的方法）在文本主题分类任务上的表现存在系统性差异
- LLM 方法在语义理解能力上可能具有优势，但也存在稳定性与成本方面的限制

---

## 方法与流程（Method / Pipeline）

本项目采用统一的处理流程：

1. 数据加载与清洗  
2. 文本预处理（如分词、向量化等）  
3. 不同方法进行文本分类推理  
4. 统一的评测指标计算  
5. 对结果进行对比与分析  

整体流程保证了不同方法在**相同条件下**进行公平对比。

---

## 基线方法（Baselines）

本项目至少包含以下两类基线方法：

### Baseline A：传统 NLP 方法
- TF-IDF 特征表示
- 线性分类器（如 Logistic Regression）

该方法作为经典文本分类基线，具有实现简单、可解释性强的特点。

### Baseline B：基于 LLM 的方法
- 使用预训练大语言模型进行文本主题分类
- 采用零样本（zero-shot）或少样本（few-shot）提示方式

该方法用于评估 LLM 在无需显式训练情况下的分类能力。

---

## 数据集（Dataset）

- 使用公开可获取的文本主题分类数据集
- 数据集包含多个主题类别
- 本项目使用数据集的子集进行实验与验证

数据集仅用于学习和实验目的。

---

## 评测指标（Metrics）

为全面评估模型性能，本项目采用以下指标：

- Accuracy
- Precision
- Recall
- F1-score

其中，F1-score 用于在类别分布不均衡的情况下，更稳健地衡量模型整体性能。

---

## 实验结果（Results）

通过统一评测框架，对不同方法的分类效果进行量化对比，并分析各方法在不同指标下的表现差异。

实验结果以表格形式呈现，便于直观比较。

---

## 项目限制与不足（Limitations）

- 数据集规模有限，结论的泛化能力存在限制
- LLM 方法对提示词（prompt）较为敏感
- 当前评测仅关注分类效果，未纳入推理延迟与计算成本
- 实验仅覆盖单一文本任务，未扩展至更多 NLP 场景

---

## 项目总结

本项目通过构建统一的评测 pipeline，对传统 NLP 方法与 LLM 方法在文本主题分类任务中的表现进行了系统性对比。
该项目强调流程完整性、评测一致性与结果可解释性，为后续更复杂的 NLP / LLM 应用提供参考。